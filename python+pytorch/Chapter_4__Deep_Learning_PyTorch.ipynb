{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "PyTorch und TensorFlow sind die beiden führenden Deep-Learning-Frameworks, und die Wahl zwischen ihnen hängt oft von den individuellen Anforderungen und Präferenzen ab. PyTorch hat aufgrund seiner Benutzerfreundlichkeit, Flexibilität und der aktiven Community viele Anhänger gefunden und wird in vielen akademischen und industriellen Projekten verwendet.\n",
    "\n",
    "PyTorch ist ein Python-Framework für maschinelles Lernen, das eine schnelle und flexible Experimentierumgebung bietet und mit einer Reihe von Werkzeugen und Bibliotheken geliefert wird, die den Einstieg erleichtern. Es wurde von Facebook AI Research entwickelt und ist auf der Grundlage der Torch-Bibliothek aufgebaut. PyTorch bietet zwei Hauptfunktionen:\n",
    "\n",
    "* Tensoren, die wie Numpy-Arrays funktionieren, aber auf der GPU ausgeführt werden.\n",
    "* Automatische Differenzierung, die eine effiziente und schnelle Berechnung von Gradienten ermöglicht\n",
    "\n",
    "PyTorch kann über den Paketmanager `pip` installiert werden:\n",
    "```bash \n",
    "pip install torch\n",
    "```\n",
    "Anschließend kann es in Python importiert werden:\n",
    "```python\n",
    "import torch\n",
    "```\n",
    "\n",
    "## Ablauf\n",
    "Meist besteht der Ablauf beim Deep Learning aus folgenden Schritten:\n",
    "1. Daten laden und aufbereiten\n",
    "2. Modell definieren\n",
    "3. Modell trainieren\n",
    "4. Modell speichern\n",
    "\n",
    "\n",
    "Wir wollen daher in diesem Kurs diese Schritte genauer betrachten. Am Ende sind Sie in der Lage ein eigenes Modell zu definieren und auf einem eigenen Datensatz zu trainieren.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Tensoren\n",
    "Bevor wir uns mit PyTorch und dem Training von Neuronalen Netzen beschäftigen, wollen wir uns mit Tensoren befassen. Tensoren sind eine Art von Datenstruktur, die verwendet wird, um Vektoren und Matrizen zu speichern. Sie sind ähnlich wie Numpy-Arrays, aber im Gegensatz zu diesen können sie auf einer GPU ausgeführt werden, um die Berechnung zu beschleunigen. Tensoren und die zugehörigen Operationen sind die grundlegenden Bausteine, die verwendet werden, um Ein- und Ausgaben sowie die Parameter eines Modells zu repräsentieren.\n",
    "\n",
    "Da wir uns bereits mit Numpy und `ndarrays` beschäftigt haben, sollte die Umstellung auf Tensoren nicht allzu schwer fallen. Die meisten Operationen, die auf Numpy-Arrays ausgeführt werden können, können auch auf Tensoren ausgeführt werden. \n",
    "\n",
    "### Erstellen von Tensoren\n",
    "Tensoren können mit der Funktion `torch.tensor()` erstellt werden. Die Funktion `torch.tensor()` akzeptiert Daten wie Listen, Numpy-Arrays und andere Tensoren. Die Funktion `torch.tensor()` hat einen Parameter `dtype`, der den Datentyp der Elemente im Tensor angibt. Wenn der Parameter `dtype` nicht angegeben wird, wird der Datentyp automatisch aus den Daten abgeleitet. Die Funktion `torch.tensor()` hat auch einen Parameter `device`, der angibt, auf welchem Gerät der Tensor erstellt werden soll. Wenn der Parameter `device` nicht angegeben wird, wird der Tensor auf der CPU erstellt. Wird ein CPU Tensor aus einem Numpy-Array erstellt, so teilen sie sich den gleichen Speicherplatz. Änderungen am Tensor wirken sich daher auch auf das Numpy-Array aus und umgekehrt. CPU Tensoren können mit der Methode `numpy()` in Numpy-Arrays umgewandelt werden.\n",
    "\n",
    "```python\n",
    "# create a tensor on the CPU from a list\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device='cpu')\n",
    "\n",
    "# create a tensor from a numpy array\n",
    "np_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = torch.from_numpy(np_array)\n",
    "np_array += 1\n",
    "print(t2) # tensor([[2, 3, 4], [5, 6, 7]], dtype=torch.int32)\n",
    "\n",
    "# create a tensor from another tensor\n",
    "t3 = torch.ones_like(t2) # create a tensor of ones with the same properties as t2\n",
    "\n",
    "# create a numpy array from a tensor\n",
    "np_array = t3.numpy()\n",
    "t3 += 1\n",
    "print(np_array) # [[2, 2, 2], \n",
    "                #  [2, 2, 2]]\n",
    "\n",
    "# print properties of tensors\n",
    "print(f'Shape of t1: {t1.shape}')       # 2x3\n",
    "print(f'Data type of t1: {t1.dtype}')   # float32\n",
    "print(f'Device of t1: {t1.device}')     # cpu\n",
    "\n",
    "```\n",
    "\n",
    "Um einen Tensor auf der GPU zu erstellen, muss der Parameter `device` auf `cuda` gesetzt werden. Tensoren können auch nachträglich auf die GPU verschoben werden, indem die Methode `to()` aufgerufen wird. Sind mehrere GPUs verfügbar, kann mit `cuda:0` die erste GPU, mit `cuda:1` die zweite GPU usw. ausgewählt werden. Beachten Sie, dass das Kopieren von Daten zwischen CPU und GPU Zeit kostet, so dass Sie die Daten nur dann auf die GPU kopieren sollten, wenn Sie sie dort verwenden wollen.\n",
    "\n",
    "\n",
    "```python\n",
    "# check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU is available')\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    print('GPU is not available')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# create a tensor on the GPU from a list\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=device)\n",
    "\n",
    "# move a tensor to the GPU\n",
    "t2 = torch.ones_like(t1, device='cpu')\n",
    "t2 = t2.to(device)\n",
    "```\n",
    "\n",
    "### Operationen mit Tensoren\n",
    "Alle von Numpy bekannten Operatoren lassen sich auch mit Tensoren durchführen. \n",
    "Für weitere Informationen zu Tensoren schauen Sie in die [Dokumentation](https://pytorch.org/docs/stable/tensors.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    " \n",
    "\n",
    "## 1. Daten laden und aufbereiten\n",
    "PyTorch bietet zwei Datenprimitive: `torch.utils.data.Dataset` und `torch.utils.data.DataLoader`, mit denen Sie sowohl vorgeladene Datensätze als auch Ihre eigenen Daten verwalten können. \n",
    "\n",
    "Ein `Dataset` repräsentiert Ihre Rohdaten und ermöglicht den Zugriff auf einzelne Datenpunkte, während ein `DataLoader` diese Daten für das Training oder die Inferenz vorbereitet, indem er sie in Mini-Batches aufteilt, das Vertauschen der Reihenfolge ermöglicht und das Laden in den Speicher effizient gestaltet. Der `DataLoader` ist eine praktische Schnittstelle, die es erleichtert, mit `Dataset`-Objekten zu arbeiten.\n",
    "\n",
    "### Dataset\n",
    "Wie in scikit-learn gibt es in PyTorch eine Reihe von Datensätzen, die Sie direkt verwenden können. Diese Datensätze sind in der `torchvision.datasets`-Klasse enthalten. Es gibt für verschiedene Anwendungsfälle verschiedene Datensätze. Die häufigsten sind `MNIST`, `CIFAR10` und `COCO`. Eine vollständige Liste der verfügbaren Datensätze finden Sie in der [Dokumentation](https://pytorch.org/vision/stable/datasets.html).\n",
    "\n",
    "#### Vordefinierte Datensätze\n",
    "Um einen vordefinierten Datensatz zu laden, muss zunächst ein `Dataset`-Objekt des gewünschten Datensatzes erstellt werden. Dieses Objekt kann dann verwendet werden, um auf die Daten zuzugreifen. Die Daten können dann mit der `torchvision.utils.make_grid()`-Funktion visualisiert werden.\n",
    "\n",
    "```python\n",
    "# import torchvision\n",
    "import torchvision\n",
    "\n",
    "# load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='data/',                    # path where the dataset is stored\n",
    "    train=True,                      # load the training split. If set to False, load the validation split\n",
    "    transform=transforms.ToTensor(), # convert images to tensors\n",
    "    download=True                    # download the dataset if it is not present on disk\n",
    ")\n",
    "\n",
    "# access the first image in the dataset\n",
    "image, label = train_dataset[0]\n",
    "print(image.shape) # torch.Size([1, 28, 28])\n",
    "print(label)       # 5\n",
    "\n",
    "# get the first 10 images in the dataset\n",
    "images = [image for image, label in [train_dataset[i] for i in range(10)]]\n",
    "\n",
    "# create a grid of images\n",
    "grid = torchvision.utils.make_grid(images, nrow=10)\n",
    "grid = grid.permute(1, 2, 0)    # change the order of the axes from CxHxW to HxWxC\n",
    "plt.imshow(grid)                # show the grid\n",
    "plt.show()                      # show the figure\n",
    "```\n",
    "\n",
    "#### Transformationen\n",
    "Häufig müssen die Daten vor dem Training aufbereitet werden. Für diesen Zweck bietet PyTorch eine Vielzahl von Transformationen an. \n",
    "Im vorherigen Beispiel wurde beim Erstellen des MNIST Datasets zum Beispiel die Transformation `transforms.ToTensor()` verwendet.\n",
    "Diese Transformation konvertiert die Daten in Tensoren. Eine vollständige Liste der verfügbaren Transformationen finden Sie in der [Dokumentation](https://pytorch.org/vision/stable/transforms.html).\n",
    "Die häufigsten Transformationen sind `transforms.ToTensor()`, `transforms.Normalize()` und `transforms.Resize()`.\n",
    "Um mehrere Transformationen nacheinander anzuwenden, können diese mit der `transforms.Compose()`-Funktion kombiniert werden.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),        # convert images to tensors\n",
    "    transforms.Normalize(         # normalize the data\n",
    "        mean=(0.5,),              # mean of the data\n",
    "        std=(0.5,)                # standard deviation of the data\n",
    "    )\n",
    "])\n",
    "\n",
    "# load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='data/',                    # path where the dataset is stored\n",
    "    train=True,                      # load the training split. If set to False, load the validation split\n",
    "    transform=transforms,            # apply the transformations\n",
    "    download=True                    # download the dataset if it is not present on disk\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Eigene Datensätze\n",
    "Um einen eigenen Datensatz zu laden, muss zunächst ein `Dataset`-Klasse erstellt werden. Diese Klasse muss von der abstrakten Klasse `torch.utils.data.Dataset` erben und die Methoden `__init__`, `__len__` und `__getitem__` überschreiben. Die Methode `__init__` wird aufgerufen, wenn ein `Dataset`-Objekt erstellt wird. Sie wird verwendet, um die Daten zu laden und aufzubereiten. Die Methode `__len__` wird aufgerufen, wenn die Funktion `len()` auf das `Dataset`-Objekt angewendet wird. Sie gibt die Anzahl der Datenpunkte im Datensatz zurück. Die Methode `__getitem__` wird aufgerufen, wenn ein Element des Datensatzes abgerufen wird. Sie gibt den Datenpunkt an der angegebenen Position zurück. \n",
    "\n",
    "```python\n",
    "# import the abstract class Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# create a custom dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, ...):\n",
    "        # load and prepare the data\n",
    "        ...\n",
    "    \n",
    "    def __len__(self):\n",
    "        # return the number of data points\n",
    "        ...\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # return the data point at the specified index\n",
    "        ...\n",
    "        return images, labels\n",
    "```\n",
    "\n",
    "\n",
    "### DataLoader\n",
    "Der `DataLoader` ist eine praktische Schnittstelle, die es erleichtert, mit `Dataset`-Objekten zu arbeiten. Er kann verwendet werden, um die Daten in Mini-Batches aufzuteilen, die Reihenfolge der Datenpunkte zu vertauschen und die Daten in den Speicher zu laden. \n",
    "\n",
    "```python\n",
    "# import the DataLoader class\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create a DataLoader object\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,                  # dataset from which to load the data\n",
    "    batch_size=64,                  # number of data points in each batch\n",
    "    shuffle=True,                   # shuffle the data\n",
    "    num_workers=4,                  # number of subprocesses to use for data loading\n",
    "    drop_last=True                  # drop the last batch if it is smaller than the specified batch size\n",
    ")\n",
    "\n",
    "# iterate over the data\n",
    "for images, labels in train_dataloader:\n",
    "    # do something with the data\n",
    "    print(images.shape) # NxCxHxW (N: batch size, C: number of channels, H: height, W: width) \n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "## 2. Modell definieren\n",
    "Nachdem wir uns mit Tensoren und dem Laden von Daten beschäftigt haben, wollen wir uns nun mit dem Definieren von Modellen beschäftigen.\n",
    "Neuronale Netze setzen sich aus mehreren Schichten/Modulen zusammen, die Operationen auf den Eingabedaten durchführen.\n",
    "Der Namespace `torch.nn` enthält alle Bausteine, die Sie zum Aufbau Ihres eigenen neuronalen Netzes benötigen. Jedes Modul in PyTorch ist eine Unterklasse der Klasse `torch.nn.Module`. Ein neuronales Netz ist selbst ein Modul, das aus anderen Modulen (Schichten) besteht. Diese verschachtelte Struktur ermöglicht die einfache Erstellung und Verwaltung komplexer Architekturen.\n",
    "\n",
    "Um ein eigenes Modell zu definieren, muss eine Klasse erstellt werden, die von der Klasse `torch.nn.Module` erbt. In der `__init__`-Methode der Klasse werden die Schichten des Netzwerks und in der `forward`-Methode die Vorwärtsberechnung des Netzwerks definiert.\n",
    "\n",
    "```python\n",
    "# import the nn module\n",
    "import torch.nn as nn\n",
    "\n",
    "# create a neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "       # define the layers of the network\n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define the forward pass\n",
    "        ...\n",
    "```\n",
    "\n",
    "Um Eingabedaten mit Hilfe des Modelles zu verarbeiten, werden diese dem Modell übergeben. Dadurch wird die `forward`-Methode des Modells zusammen mit einigen Hintergrundoperationen ausgeführt. Rufen Sie `model.forward()` nicht direkt auf! \n",
    "\n",
    "```python\n",
    "# create a model\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# create a random input tensor\n",
    "inpt = torch.randn(64, 28*28, device=device, dtype=torch.float32)) \n",
    "\n",
    "# get the output of the model\n",
    "output = model(inpt)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Schichten\n",
    "Die meisten Modelle bestehen aus mehreren Schichten. PyTorch hat Module in der `torch.nn`-Klasse, die verschiedene Arten von Schichten darstellen. Eine vollständige Liste der verfügbaren Module finden Sie in der [Dokumentation](https://pytorch.org/docs/stable/nn.html). Die häufigsten Module sind `nn.Linear`, `nn.ReLU`, `nn.Sigmoid`, `nn.Softmax`, `nn.Sequential`, `nn.Flatten`, `nn.Dropout`, `nn.MaxPool2d`, `nn.AvgPool2d` und `nn.Conv2d`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "```\n",
    "\n",
    "\n",
    "### Modell-Zoo\n",
    "Ein großer Vorteil von PyTorch ist der Modell-Zoo. Dieser enthält bekannte vortrainierte Modelle, die Sie direkt verwenden können. Eine vollständige Liste der verfügbaren Modelle finden Sie in der [Dokumentation](https://pytorch.org/vision/stable/models.html). Bekannte Klassifikations-Modelle sind zB `VGG`, `ResNet` und `Inception`.\n",
    "\n",
    "```python\n",
    "import torchvision.models as models\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "# load a predefined model (not pretrained)\n",
    "model = models.vgg16()\n",
    "\n",
    "# load a pretrained model\n",
    "model = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "```\n",
    "\n",
    "<!-- ![VGG16](images/pytorch/VGG16.png) -->\n",
    "<center><img src=\"images/pytorch/VGG16.png\" alt=\"VGG16\" width=\"500\"/></center>\n",
    "\n",
    "#### Letzte Schicht ersetzen\n",
    "Soll ein vortrainiertes Netz für eine andere Aufgabe verwendet werden, so muss oft die letzte Schicht ersetzt werden, da sich die Anzahl der Klassen geändert hat. So hat zB der ImageNet Datenstz 1000 Klassen, aber wir wollen nur 10 Klassen klassifizieren.\n",
    "Dazu muss zunächst überprüft werden, wie die letzte Schicht implementiert wurde. In PyTorch kann der Aufbau eines Netzes mit der `print` Funktion ausgegeben werden. \n",
    "\n",
    "```python\n",
    "# load a pretrained model\n",
    "model = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# print the model\n",
    "print(model)\n",
    "```\n",
    "Dies führt zur Folgenden Ausgabe:\n",
    "```\n",
    "VGG(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (3): ReLU(inplace=True)\n",
    "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (6): ReLU(inplace=True)\n",
    "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (8): ReLU(inplace=True)\n",
    "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (11): ReLU(inplace=True)\n",
    "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (13): ReLU(inplace=True)\n",
    "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (15): ReLU(inplace=True)\n",
    "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (18): ReLU(inplace=True)\n",
    "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (20): ReLU(inplace=True)\n",
    "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (22): ReLU(inplace=True)\n",
    "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (25): ReLU(inplace=True)\n",
    "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (27): ReLU(inplace=True)\n",
    "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (29): ReLU(inplace=True)\n",
    "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Dropout(p=0.5, inplace=False)\n",
    "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "    (4): ReLU(inplace=True)\n",
    "    (5): Dropout(p=0.5, inplace=False)\n",
    "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "  )\n",
    ")\n",
    "```\n",
    "\n",
    "Die letzte Schicht ist ein `nn.Linear`-Modul mit 4096 Eingängen und 1000 Ausgängen. Um die letzte Schicht zu ersetzen, muss ein neues `nn.Linear`-Modul erstellt werden, das 4096 Eingänge und 10 Ausgänge hat. Anschließend muss das neue Modul an die richtige Stelle im Modell eingefügt werden.\n",
    "    \n",
    "```python\n",
    "# load a pretrained model\n",
    "model = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# replace the last layer\n",
    "model.classifier[6] = nn.Linear(4096, 10)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## 3. Optimierung\n",
    "Haben wir ein Modell definiert, müssen wir dieses anschließend trainieren. Dazu müssen wir zunächst einen Optimierer auswählen. Ein Optimierer ist ein Objekt, das die Parameter des Modells aktualisiert. Die meisten Optimierer verwenden den Gradienten der Verlustfunktion, um die Parameter zu aktualisieren. Der Gradient wird mit Hilfe der automatischen Differenzierung berechnet. PyTorch bietet eine Reihe von Optimierern in der `torch.optim`-Klasse an. Eine vollständige Liste der verfügbaren Optimierer finden Sie in der [Dokumentation](https://pytorch.org/docs/stable/optim.html). Die häufigsten Optimierer sind `optim.SGD` und `optim.Adam`.\n",
    "\n",
    "```python\n",
    "import torch.optim as optim\n",
    "\n",
    "# create an optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "```\n",
    "\n",
    "Der Optimierer wird mit den Parametern des Modells initialisiert. Die Methode `model.parameters()` gibt eine Liste aller Parameter des Modells zurück. Der Parameter `lr` gibt die Lernrate an. Die Lernrate bestimmt, wie stark die Parameter aktualisiert werden. Eine zu hohe Lernrate kann dazu führen, dass das Modell nicht konvergiert, während eine zu niedrige Lernrate zu einem langsamen Training führt. Die Lernrate ist ein Hyperparameter, der experimentell bestimmt werden muss. Verschiedene Optimierer haben verschiedene Hyperparameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Verlustfunktion\n",
    "Die Verlustfunktion (auch als Kostenfunktion oder Fehlerfunktion bezeichnet) ist eine mathematische Funktion, die verwendet wird, um die Abweichung zwischen den tatsächlichen Daten und den vorhergesagten Daten zu quantifizieren. Die Verlustfunktion spielt eine entscheidende Rolle im Trainingsprozess eines Modells. PyTorch bietet eine Reihe von Verlustfunktionen in der `torch.nn`-Klasse an. Eine vollständige Liste der verfügbaren Verlustfunktionen finden Sie in der [Dokumentation](https://pytorch.org/docs/stable/nn.html#loss-functions). Die häufigsten Verlustfunktionen sind `nn.MSELoss`, `nn.CrossEntropyLoss` und `nn.NLLLoss`.\n",
    "\n",
    "```python\n",
    "# create a loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training\n",
    "Das Training geschieht iterativ in einem sogenannten Trainingsloop. In jedem Schritt des Trainingsloops werden die folgenden Schritte ausgeführt:\n",
    "1. Eingabedaten und zugehörige Labels laden\n",
    "2. Vorwärtsberechnung durchführen\n",
    "3. Verlust berechnen\n",
    "4. Gradienten berechnen\n",
    "5. Parameter aktualisieren\n",
    "\n",
    "```python\n",
    "# set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# iterate over the data\n",
    "for images, labels in train_dataloader:\n",
    "    # move the data to the device\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    output = model(images)\n",
    "\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, labels)\n",
    "\n",
    "    # zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass \n",
    "    # calculate the gradient of the loss with respect to the parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update the parameters\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "Der Durchlauf durch die Traingsdaten wird als Epoche bezeichnet. Die Anzahl der Epochen ist ebenfalls ein Hyperparameter. Nach jeder Epoche kann das Modell auf den Validierungsdaten getestet werden. Dies geschieht in einem sogenannten Validierungsloop. In jedem Schritt des Validierungsloops werden die folgenden Schritte ausgeführt:\n",
    "1. Eingabedaten und zugehörige Labels laden\n",
    "2. Vorwärtsberechnung durchführen\n",
    "3. Verlust berechnen\n",
    "4. Genauigkeit berechnen\n",
    "\n",
    "```python\n",
    "# set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    # iterate over the data\n",
    "    for images, labels in val_dataloader:\n",
    "        # move the data to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        output = model(images)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # calculate the accuracy\n",
    "        accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Visualisierung\n",
    "Um den Trainingsfortschritt zu überwachen, können die Verluste und Genauigkeiten während des Trainings und der Validierung gespeichert und über die Epoche gemittelt werden. Diese Werte können dann mit Hilfe von Diagrammen visualisiert werden. In den vorherigen Übungen haben Sie die Bibliothek `matplotlib` kennengelernt. Diese Bibliothek kann beispielsweise für die Visualisierung der Verluste und Genauigkeiten verwendet werden.\n",
    "\n",
    "```python\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the losses\n",
    "ax.plot(train_losses, label='train')\n",
    "ax.plot(val_losses, label='val')\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "def visualize_data(data:dict):\n",
    "    \"\"\"\n",
    "    Visualize the data in a dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    # clear the current figure\n",
    "    plt.clf()\n",
    "\n",
    "    for idx, metric in enumerate(data.keys()):\n",
    "        plt.subplot(1, 2, idx+1)\n",
    "        plt.title(metric)\n",
    "        for phase in data[metric].keys():\n",
    "            plt.plot(data[metric][phase], label=f'{phase} {metric}')\n",
    "            plt.legend()\n",
    "    plt.suptitle('Training Metrics')\n",
    "\n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "\n",
    "#### Tensorboard\n",
    "Eine weitere Möglichkeit der Visualisierung ist Tensorboard. Tensorboard ist ein Tool zur Visualisierung von Daten, die während des Trainings gesammelt wurden. Es wurde ursprünglich für TensorFlow entwickelt, kann aber auch mit PyTorch verwendet werden. Tensorboard kann mit der Bibliothek `tensorboard` installiert werden:\n",
    "```bash\n",
    "pip install tensorboard\n",
    "```\n",
    "Anschließend kann es in Python importiert werden:\n",
    "```python\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "```\n",
    "\n",
    "Um Daten in Tensorboard zu visualisieren, müssen diese zunächst in ein `SummaryWriter`-Objekt geschrieben werden. Dieses Objekt kann dann verwendet werden, um die Daten in Tensorboard zu visualisieren. \n",
    "\n",
    "```python\n",
    "# create a SummaryWriter object\n",
    "writer = SummaryWriter('runs/mnist_experiment_1')\n",
    "\n",
    "# write the loss to Tensorboard\n",
    "writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "```\n",
    "\n",
    "Neben Skalaren können auch Bilder, Histogramme, Graphen und Texte in Tensorboard visualisiert werden. Eine vollständige Liste der verfügbaren Funktionen finden Sie in der [Dokumentation](https://pytorch.org/docs/stable/tensorboard.html).\n",
    "\n",
    "Um Tensorboard zu starten, muss der folgende Befehl ausgeführt werden:\n",
    "```bash\n",
    "tensorboard --logdir=path_to_runs --port=6006 --bind_all\n",
    "```\n",
    "Tensorboard kann dann im Browser unter der Adresse `http://im-kigs.oth-regensburg.de:6006` aufgerufen werden. Da wir alle auf dem selben Server arbeiten müssen wir unterschiedliche Ports verwenden. Verwenden Sie daher die Nummer ihrer Kennung (abc12345) als Port für Tensorboard.\n",
    "\n",
    "#### Interpretation der Ergebnisse\n",
    "Die Visualisierungen können verwendet werden, um den Trainingsfortschritt zu überwachen und zu verstehen, wie das Modell funktioniert. Der Fehler und die Genauigkeit auf den Trainingsdaten und den Validierungsdaten sollte sich im Laufe der Zeit ändern. Wenn der Fehler auf den Trainingsdaten sinkt, aber auf den Validierungsdaten steigt, ist das Modell wahrscheinlich überangepasst (overfitting). Wenn der Fehler auf den Trainingsdaten und den Validierungsdaten steigt oder stagniert, ist das Modell wahrscheinlich unterangepasst (underfitting). \n",
    " \n",
    "<img src=\"images/pytorch/Under_Overfitting.png\" alt=\"loss\" width=\"500\"/>\n",
    "\n",
    "Im Falle von Underfitting kann das Modell komplexer gestaltet werden, indem zB mehr Schichten oder mehr Neuronen pro Schicht hinzugefügt werden. Im Falle von Overfitting kann das Modell vereinfacht werden oder es können Regularisierungstechniken wie Dropout verwendet werden.\n",
    "\n",
    "Ebenfalls lässt sich die Wahl der Lernrate einordnen. Wenn die Lernrate zu hoch ist, kann das Training instabil werden, da die Gewichtsaktualisierungen zu groß sind und das Modell möglicherweise über die Minima des Fehlerfunktion springt. Dies kann dazu führen, dass der Fehler auf den Trainingsdaten schnell sinkt, aber auf den Validierungsdaten ansteigt, da das Modell nicht gut generalisiert. Ist die Lernrate zu niedrig, kann das Training sehr langsam sein und in einem lokalen Minima steckenbleiben. In diesem Fall wird der Fehler sowohl auf den Trainingsdaten als auch auf den Validierungsdaten nur langsam sinken, und es kann viel Zeit erfordern, bis das Modell konvergiert.\n",
    "\n",
    "<img src=\"images/pytorch/Learning_Rate.png\" alt=\"loss\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Modell speichern\n",
    "\n",
    "Ein trainiertes Modell kann mit der `torch.save()`-Funktion gespeichert werden. Diese Funktion speichert die Parameter des Modells in einer Datei. Die Datei kann dann mit der `torch.load()`-Funktion geladen werden. Die Funktion `torch.save()` akzeptiert zwei Parameter: das Modell und den Dateinamen. Der Dateiname sollte die Endung `.pt` oder `.pth` haben.\n",
    "\n",
    "```python\n",
    "# save the model\n",
    "torch.save(model, 'model.pt')\n",
    "\n",
    "# load the model\n",
    "model = torch.load('model.pt')\n",
    "```\n",
    "\n",
    "Üblicherweise soll nicht das Modell selbst, sondern nur die Parameter gespeichert werden. Dies kann mit dem `state_dict` des Modells erreicht werden. Das `state_dict` ist ein Python-Wörterbuch, das jedem Parameter einen eindeutigen Schlüssel zuordnet. Das `state_dict` kann mit der Methode `model.state_dict()` abgerufen werden. Die Methode `model.load_state_dict()` kann verwendet werden, um das `state_dict` in ein Modell zu laden. Häufig werden neben den Modellparametern auch weitere Informationen wie die Anzahl der Epochen, der Optimierer und die Verlustfunktion gespeichert. Diese Informationen können in einem Python-Wörterbuch gespeichert werden und zusammen mit dem `state_dict` gespeichert werden.\n",
    "\n",
    "\n",
    "```python\n",
    "# create a dictionary with the model parameters and additional information\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss\n",
    "}\n",
    "\n",
    "# save the dictionary\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "\n",
    "# load the dictionary\n",
    "checkpoint = torch.load('checkpoint.pth')\n",
    "\n",
    "# load the model parameters\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# load the optimizer parameters\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# load the loss\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "# load the epoch\n",
    "epoch = checkpoint['epoch']\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Aufgaben\n",
    "1. Laden Sie den MNIST Datensatz und visualisieren Sie die ersten 10 Bilder.\n",
    "2. Definieren Sie ein Modell mit zwei linearen Schichten und einer ReLU-Aktivierungsfunktion. Trainieren Sie das Modell für 10 Epochen und visualisieren Sie die Verluste und Genauigkeiten während des Trainings und der Validierung.\n",
    "3. Ändern Sie Ihr Modell in ein CNN. Trainieren Sie das Modell für 10 Epochen und visualisieren Sie die Verluste und Genauigkeiten während des Trainings und der Validierung.\n",
    "4. Speichern Sie während dem Training das beste Modell. Laden Sie das beste Modell nach dem Training und testen Sie es auf den Validierungsdaten.\n",
    "5. Schreiben Sie sich eine eigene `Dataset`-Klasse.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        #  define the layers\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # flatten the input\n",
    "\n",
    "        # define the forward pass\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # define conv layers (feature extractor)\n",
    "\n",
    "        # define the pooling layer\n",
    "\n",
    "        # define the fully connected layers (classifier)\n",
    "\n",
    "        # define the activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definte training loop\n",
    "def train_loop(model, criterion, optimizer, train_dataloader, device):\n",
    "    # set the model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # summaraize the loss and accuracy\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    # iterate over the data\n",
    "    for images, labels in train_dataloader:\n",
    "       \n",
    "        '''\n",
    "            TODO: Complete the training loop\n",
    "        '''\n",
    "\n",
    "        # calculate the accuracy\n",
    "        accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "        # accumulate the loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += accuracy.item()\n",
    "\n",
    "    num_batches = len(train_dataloader)\n",
    "    return epoch_loss/num_batches, epoch_accuracy/num_batches\n",
    "\n",
    "\n",
    "def valid_loop(model, criterion, val_dataloader, device):\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # summaraize the loss and accuracy\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    # disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # iterate over the data\n",
    "        for images, labels in val_dataloader:\n",
    "            '''\n",
    "                TODO: Complete the validation loop \n",
    "            '''\n",
    "\n",
    "            # calculate the accuracy\n",
    "            accuracy = (output.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "            # accumulate the loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "\n",
    "\n",
    "    num_batches = len(val_dataloader)\n",
    "    return epoch_loss/num_batches, epoch_accuracy/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the MNIST dataset\n",
    "# create a dataset\n",
    "train_dataset = None\n",
    "valid_dataset = None\n",
    "\n",
    "\n",
    "# create a dataloader\n",
    "train_loader = None\n",
    "valid_loader = None\n",
    "\n",
    "\n",
    "# define the loss function\n",
    "criterion = None\n",
    "\n",
    "\n",
    "# define model\n",
    "model = None\n",
    "\n",
    "\n",
    "# define hyperparameters\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = None\n",
    "\n",
    "\n",
    "# define the device\n",
    "device = None\n",
    "\n",
    "# dictionary to store the metrics\n",
    "metrics = {m: {p:[] for p in ['train', 'val']} for m in ['loss', 'acc']}\n",
    "\n",
    "# use a nice progress bar to visualize the training progress\n",
    "pbar = tqdm(range(num_epochs))\n",
    "\n",
    "# train the model for num_epochs epochs\n",
    "for ep in pbar:\n",
    "    # set a description for the progress bar\n",
    "    pbar.set_description(f'Epoch: {ep+1}/{num_epochs}')\n",
    "\n",
    "    # call the train and valid loops\n",
    "    train_loss, train_acc = train_loop(model, criterion, optimizer, train_loader, device)\n",
    "    val_loss, val_acc     = valid_loop(model, criterion, valid_loader, device)\n",
    "\n",
    "    # store the metrics\n",
    "    metrics['loss']['train'].append(train_loss)\n",
    "    metrics['loss']['val'].append(val_loss)\n",
    "    metrics['acc']['train'].append(train_acc)\n",
    "    metrics['acc']['val'].append(val_acc)\n",
    "\n",
    "    # update the progress bar with the metrics from the current epoch\n",
    "    pbar.set_postfix({'Train Loss':f'{train_loss:.2f}', 'Val Loss':f'{val_loss:.2f}', 'Train Acc':f'{train_acc:.2f}', 'Val Acc':f'{val_acc:.2f}'})\n",
    "pbar.close()\n",
    "\n",
    "# visualize the logged metrics over the whole training process\n",
    "visualize_data(metrics)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
