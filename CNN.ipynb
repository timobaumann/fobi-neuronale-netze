{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da508c8f-8412-453c-8832-7a4bd2402d46",
   "metadata": {},
   "source": [
    "Code-Fragment f√ºr CNN-basiertes MNIST-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821c3e12-623a-49b0-9200-be784d5533b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "class MNISTClassify(nn.Module):\n",
    "    \"\"\"works much better with CNNs.\n",
    "    shamefully stolen/borrowed from https://github.com/mbjoseph/pytorch-mnist/blob/master/cnn-mnist.ipynb\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MNISTClassify, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=5)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x, isTrain=False):\n",
    "        x = x.reshape((1,1,28,28))\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=-1)\n",
    "        return x.view((10))\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539ba3e6-6ec5-4c3f-80e1-7a21680aee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MNISTClassify(nn.Module):\n",
    "    \"\"\"works much better with CNNs.\n",
    "    shamefully stolen/borrowed from https://github.com/mbjoseph/pytorch-mnist/blob/master/cnn-mnist.ipynb\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MNISTClassify, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 120)\n",
    "        self.fc1_drop = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x, isTrain=False):\n",
    "        x = x.reshape((1,1,28,28))\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1_drop(self.fc1(x)))\n",
    "        x = F.log_softmax(self.fc2(x), dim=-1)\n",
    "        return x.view((10))\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725eb6b5-bd59-4c95-9f7e-f4d3f31b4237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
